apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: preprocessing-pipeline-2-
  annotations:
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.14
    pipelines.kubeflow.org/pipeline_compilation_time: '2022-11-15T12:51:18.371841'
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Test to create the pipeline",
      "inputs": [{"default": "gs://titanic-challenge/train.csv", "name": "path", "optional":
      true, "type": "String"}, {"default": "gs://titanic-challenge/artifacts", "name":
      "pipeline-root"}, {"default": "pipeline/preprocessing-pipeline", "name": "pipeline-name"}],
      "name": "preprocessing-pipeline"}'
    pipelines.kubeflow.org/v2_pipeline: "true"
  labels:
    pipelines.kubeflow.org/v2_pipeline: "true"
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.14
spec:
  entrypoint: preprocessing-pipeline-2
  templates:
  - name: feature-engineering
    container:
      args:
      - sh
      - -c
      - |2

        if ! [ -x "$(command -v pip)" ]; then
            python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
        fi

        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'numpy' 'fsspec' 'gcsfs' 'kfp==1.8.14' && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp -d)
        printf "%s" "$0" > "$program_path/ephemeral_component.py"
        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
      - |2+

        import kfp
        from kfp.v2 import dsl
        from kfp.v2.dsl import *
        from typing import *

        def feature_engineering(path: InputPath(Dataset), train_dataset: OutputPath(Dataset)):

            import pandas as pd
            import re

            df = pd.read_csv(path)
            drop_cabin = False
            decks = {"A": 1, "B": 2, "C": 3, "D": 4, "E": 5, "F": 6, "G": 7, "U": 8}
            df['Cabin'] = df['Cabin'].fillna('U0')
            df['Deck'] = df['Cabin'].apply(lambda x: re.compile("([a-zA-Z]+)").search(x).group())
            df['Deck'] = df['Deck'].map(decks)
            df['Deck'] = df['Deck'].fillna(0)
            df['Deck'] = df['Deck'].astype(int)

            if drop_cabin:
                df.drop(['Cabin'], axis=1)

            drop_name = False
            df['Title'] = df['Name'].str.extract('([A-Za-z]+)\.', expand=False)
            df['Title'] = df['Title'].replace(
                ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other'
            )
            df['Title'] = df['Title'].replace('Mlle', 'Miss')
            df['Title'] = df['Title'].replace('Ms', 'Miss')
            df['Title'] = df['Title'].replace('Mme', 'Mrs')

            if drop_name:
                df.drop(['Name'], axis=1, inplace=True)

            sex_dict = {"male": 0, "female": 1}
            df['Sex'] = df['Sex'].map(sex_dict)

            df['Relatives'] = df['SibSp'] + df['Parch']
            drop_features = False
            if drop_features:
                df.drop(['SibSp', 'Parch'], axis=1, inplace=True)

            columns = ['Cabin', 'Name', 'Ticket', 'SibSp', 'Parch']
            df.drop(columns,axis=1, inplace=True)

            encoded_ports = {'S': 0, 'C': 1, 'Q': 2}

            df['Embarked'] = df['Embarked'].map(encoded_ports)

            df.loc[df['Fare'] <= 7.91, 'Fare'] = 0
            df.loc[(df['Fare'] > 7.91) & (df['Fare'] <= 14.454), 'Fare'] = 1
            df.loc[(df['Fare'] > 14.454) & (df['Fare'] <= 31), 'Fare'] = 2
            df.loc[(df['Fare'] > 31) & (df['Fare'] <= 99), 'Fare'] = 3
            df.loc[(df['Fare'] > 99) & (df['Fare'] <= 250), 'Fare'] = 4
            df.loc[df['Fare'] > 250, 'Fare'] = 5
            df['Fare'] = df['Fare'].astype(int)

            df['Age'] = df['Age'].astype(int)

            df.loc[df['Age'] <= 11, 'Age'] = 0
            df.loc[(df['Age'] > 11) & (df['Age'] <= 18), 'Age'] = 1
            df.loc[(df['Age'] > 18) & (df['Age'] <= 22), 'Age'] = 2
            df.loc[(df['Age'] > 22) & (df['Age'] <= 27), 'Age'] = 3
            df.loc[(df['Age'] > 27) & (df['Age'] <= 33), 'Age'] = 4
            df.loc[(df['Age'] > 33) & (df['Age'] <= 40), 'Age'] = 5
            df.loc[(df['Age'] > 40) & (df['Age'] <= 66), 'Age'] = 6
            df.loc[df['Age'] > 66, 'Age'] = 7

            titles_dic = {"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5}
            df['Title'] = df['Title'].map(titles_dic)
            df['Title'] = df['Title'].fillna(0)

            df['Age_Class'] = df['Age'] * df['Pclass']
            print(df.head())

            df.to_csv(train_dataset, index=False)

      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - feature_engineering
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, feature-engineering, --pipeline_name,
        '{{inputs.parameters.pipeline-name}}', --run_id, $(KFP_RUN_ID), --run_resource,
        workflows.argoproj.io/$(WORKFLOW_ID), --namespace, $(KFP_NAMESPACE), --pod_name,
        $(KFP_POD_NAME), --pod_uid, $(KFP_POD_UID), --pipeline_root, '{{inputs.parameters.pipeline-root}}',
        --enable_caching, $(ENABLE_CACHING), --, --]
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      - {name: KFP_V2_IMAGE, value: 'python:3.7'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {}, "inputArtifacts":
          {"path": {"metadataPath": "/tmp/inputs/path/data", "schemaTitle": "system.Dataset",
          "instanceSchema": "", "schemaVersion": "0.0.1"}}, "outputParameters": {},
          "outputArtifacts": {"train_dataset": {"schemaTitle": "system.Dataset", "instanceSchema":
          "", "schemaVersion": "0.0.1", "metadataPath": "/tmp/outputs/train_dataset/data"}}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: python:3.7
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - {name: pipeline-name}
      - {name: pipeline-root}
      artifacts:
      - {name: preprocessing-pipeline-dataset, path: /tmp/inputs/path/data}
    outputs:
      artifacts:
      - {name: feature-engineering-train_dataset, path: /tmp/outputs/train_dataset/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{}'
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.14
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/enable_caching: "true"
    initContainers:
    - command: [launcher, --copy, /kfp-launcher/launch]
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
  - name: ml-pipeline
    container:
      args:
      - sh
      - -c
      - |2

        if ! [ -x "$(command -v pip)" ]; then
            python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
        fi

        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'numpy' 'fsspec' 'gcsfs' 'scikit-learn' 'kfp==1.8.14' && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp -d)
        printf "%s" "$0" > "$program_path/ephemeral_component.py"
        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
      - |2+

        import kfp
        from kfp.v2 import dsl
        from kfp.v2.dsl import *
        from typing import *

        def ml_pipeline(path: InputPath(Dataset)) -> float:

            import pandas as pd
            from sklearn.tree import DecisionTreeClassifier

            df = pd.read_csv(path)

            x_train = df.drop(['Survived'], axis=1)
            y_train = df['Survived']

            model = DecisionTreeClassifier()
            model.fit(x_train, y_train)

            accuracy = model.score(x_train, y_train)
            print(accuracy)
            accuracy = round(accuracy * 100, 2)

            return accuracy

      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - ml_pipeline
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, ml-pipeline, --pipeline_name,
        '{{inputs.parameters.pipeline-name}}', --run_id, $(KFP_RUN_ID), --run_resource,
        workflows.argoproj.io/$(WORKFLOW_ID), --namespace, $(KFP_NAMESPACE), --pod_name,
        $(KFP_POD_NAME), --pod_uid, $(KFP_POD_UID), --pipeline_root, '{{inputs.parameters.pipeline-root}}',
        --enable_caching, $(ENABLE_CACHING), --, --]
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      - {name: KFP_V2_IMAGE, value: 'python:3.7'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {}, "inputArtifacts":
          {"path": {"metadataPath": "/tmp/inputs/path/data", "schemaTitle": "system.Dataset",
          "instanceSchema": "", "schemaVersion": "0.0.1"}}, "outputParameters": {"Output":
          {"type": "DOUBLE", "path": "/tmp/outputs/Output/data"}}, "outputArtifacts":
          {}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: python:3.7
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - {name: pipeline-name}
      - {name: pipeline-root}
      artifacts:
      - {name: feature-engineering-train_dataset, path: /tmp/inputs/path/data}
    outputs:
      artifacts:
      - {name: ml-pipeline-Output, path: /tmp/outputs/Output/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{}'
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.14
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/enable_caching: "true"
    initContainers:
    - command: [launcher, --copy, /kfp-launcher/launch]
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
  - name: preprocessing-pipeline
    container:
      args:
      - sh
      - -c
      - |2

        if ! [ -x "$(command -v pip)" ]; then
            python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
        fi

        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'numpy' 'fsspec' 'gcsfs' 'kfp==1.8.14' && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp -d)
        printf "%s" "$0" > "$program_path/ephemeral_component.py"
        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
      - |2+

        import kfp
        from kfp.v2 import dsl
        from kfp.v2.dsl import *
        from typing import *

        def preprocessing_pipeline(path: str, dataset: OutputPath(Dataset)):

            import pandas as pd
            import numpy as np
            df = pd.read_csv(path)

            columns = ['PassengerId']
            df.drop(columns, axis=1, inplace=True)

            mean = df['Age'].mean()
            std = df['Age'].std()
            total_nulls = df['Age'].isnull().sum()

            randon_age_range = np.random.randint(mean - std, mean + std, size=total_nulls)
            age_feat_slice = df['Age'].copy()
            age_feat_slice[np.isnan(age_feat_slice)] = randon_age_range

            df['Age'] = age_feat_slice
            df['Age'] = df['Age'].astype(int)

            common_val = 'S'

            df['Embarked'] = df['Embarked'].fillna(common_val)
            df['Fare'] = df['Fare'].fillna(0)
            df['Fare'] = df['Fare'].astype(int)

            df.to_csv(dataset, index=False)

      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - preprocessing_pipeline
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, preprocessing-pipeline, --pipeline_name,
        '{{inputs.parameters.pipeline-name}}', --run_id, $(KFP_RUN_ID), --run_resource,
        workflows.argoproj.io/$(WORKFLOW_ID), --namespace, $(KFP_NAMESPACE), --pod_name,
        $(KFP_POD_NAME), --pod_uid, $(KFP_POD_UID), --pipeline_root, '{{inputs.parameters.pipeline-root}}',
        --enable_caching, $(ENABLE_CACHING), --, 'path={{inputs.parameters.path}}',
        --]
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      - {name: KFP_V2_IMAGE, value: 'python:3.7'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {"path": {"type":
          "STRING"}}, "inputArtifacts": {}, "outputParameters": {}, "outputArtifacts":
          {"dataset": {"schemaTitle": "system.Dataset", "instanceSchema": "", "schemaVersion":
          "0.0.1", "metadataPath": "/tmp/outputs/dataset/data"}}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: python:3.7
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - {name: path}
      - {name: pipeline-name}
      - {name: pipeline-root}
    outputs:
      artifacts:
      - {name: preprocessing-pipeline-dataset, path: /tmp/outputs/dataset/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{}'
        pipelines.kubeflow.org/arguments.parameters: '{"path": "{{inputs.parameters.path}}"}'
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.14
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/enable_caching: "true"
    initContainers:
    - command: [launcher, --copy, /kfp-launcher/launch]
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
  - name: preprocessing-pipeline-2
    inputs:
      parameters:
      - {name: path}
      - {name: pipeline-name}
      - {name: pipeline-root}
    dag:
      tasks:
      - name: feature-engineering
        template: feature-engineering
        dependencies: [preprocessing-pipeline]
        arguments:
          parameters:
          - {name: pipeline-name, value: '{{inputs.parameters.pipeline-name}}'}
          - {name: pipeline-root, value: '{{inputs.parameters.pipeline-root}}'}
          artifacts:
          - {name: preprocessing-pipeline-dataset, from: '{{tasks.preprocessing-pipeline.outputs.artifacts.preprocessing-pipeline-dataset}}'}
      - name: ml-pipeline
        template: ml-pipeline
        dependencies: [feature-engineering]
        arguments:
          parameters:
          - {name: pipeline-name, value: '{{inputs.parameters.pipeline-name}}'}
          - {name: pipeline-root, value: '{{inputs.parameters.pipeline-root}}'}
          artifacts:
          - {name: feature-engineering-train_dataset, from: '{{tasks.feature-engineering.outputs.artifacts.feature-engineering-train_dataset}}'}
      - name: preprocessing-pipeline
        template: preprocessing-pipeline
        arguments:
          parameters:
          - {name: path, value: '{{inputs.parameters.path}}'}
          - {name: pipeline-name, value: '{{inputs.parameters.pipeline-name}}'}
          - {name: pipeline-root, value: '{{inputs.parameters.pipeline-root}}'}
  arguments:
    parameters:
    - {name: path, value: 'gs://titanic-challenge/train.csv'}
    - {name: pipeline-root, value: 'gs://titanic-challenge/artifacts'}
    - {name: pipeline-name, value: pipeline/preprocessing-pipeline}
  serviceAccountName: pipeline-runner
